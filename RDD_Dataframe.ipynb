{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Configuração de bibliotecas no Pycharm",
   "id": "134e073826cfe463"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Criando a sessão do SparkContext e SparkSession",
   "id": "1b525826a6a870b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T18:10:37.390115Z",
     "start_time": "2025-02-12T18:10:37.377281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ],
   "id": "3cc83ceeaf26006c",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T18:10:37.407155Z",
     "start_time": "2025-02-12T18:10:37.400123Z"
    }
   },
   "cell_type": "code",
   "source": "sc = SparkContext.getOrCreate()",
   "id": "5a3f87efea6afd03",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T18:10:37.454759Z",
     "start_time": "2025-02-12T18:10:37.432109Z"
    }
   },
   "cell_type": "code",
   "source": "spark = SparkSession.builder.appName('PySpark DataFrame From RDD').getOrCreate()",
   "id": "9d1bd0ad22154ee9",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Criando PySpark DataFrame para RDD",
   "id": "39b0a9458cb87b5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T18:17:19.364377Z",
     "start_time": "2025-02-12T18:17:19.307360Z"
    }
   },
   "cell_type": "code",
   "source": "rdd = sc.parallelize([('C', 83, 76, 87, 90), ('A', 91, 89, 81, 85), ('B', 85, 88, 79, 83), ('D', 78, 89, 88, 87), ('E', 90, 82, 85, 89)])",
   "id": "e23976cef4a069ca",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T18:17:21.045995Z",
     "start_time": "2025-02-12T18:17:21.039590Z"
    }
   },
   "cell_type": "code",
   "source": "print(type(rdd))",
   "id": "3dde6a3d13b5b6fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T18:17:22.401084Z",
     "start_time": "2025-02-12T18:17:22.395193Z"
    }
   },
   "cell_type": "code",
   "source": "sub = ['id_person', 'Value_1', 'Value_2', 'Value_3', 'Value_4']",
   "id": "b5d4dda690133960",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-12T18:17:23.805775Z",
     "start_time": "2025-02-12T18:17:23.800951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "    print(f\"Número de colunas no esquema: {len(sub)}\")\n",
    "    print(f\"Colunas no esquema: {sub}\")\n",
    "    print()"
   ],
   "id": "fb9e3b208550df64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de colunas no esquema: 5\n",
      "Colunas no esquema: ['id_person', 'Value_1', 'Value_2', 'Value_3', 'Value_4']\n",
      "\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "marks_df = spark.createDataFrame(rdd, schema=sub)",
   "id": "f440a66fa35541d4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
